{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This codes check the Drugbank database and see which of the 100 drugs are availbale, and then save the available drug as \"[Drugbank Data](drug_validation_results.json)\n",
    "\n",
    "#### The main drugbank dataset is not included due to license restrictions, but can be gotten from https://go.drugbank.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded DrugBank data with 16581 entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Summary:\n",
      "Total drugs checked: 100\n",
      "Found in DrugBank: 99\n",
      "Missing from DrugBank: 1\n",
      "\n",
      "Results saved to drug_validation_results.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "\n",
    "class DrugValidationFramework:\n",
    "    def __init__(self):\n",
    "        # Drug name mappings for known alternatives\n",
    "        self.drug_aliases = {\n",
    "            \"Albuterol\": [\"Salbutamol\"],\n",
    "            \"Trimethoprim-sulfamethoxazole\": [\"Bactrim\", \"Co-trimoxazole\", \"TMP-SMX\", \"SXT,\", \"TMP-SMZ\", \" TMP-Sulfa\"],\n",
    "            \"Mycophenolate\": [\"Mycophenolic acid\", \"Mycophenolate mofetil\"],\n",
    "        }\n",
    "        \n",
    "        # Organized dictionary of 100 selected drugs for validation\n",
    "        self.drug_categories = {\n",
    "            \"Cardiovascular\": {\n",
    "                \"Antihypertensives\": [\"Lisinopril\", \"Amlodipine\", \"Metoprolol\", \"Valsartan\", \"Hydrochlorothiazide\"],\n",
    "                \"Anticoagulants\": [\"Warfarin\", \"Apixaban\", \"Clopidogrel\", \"Rivaroxaban\", \"Dabigatran\"],\n",
    "                \"Statins\": [\"Atorvastatin\", \"Simvastatin\", \"Rosuvastatin\", \"Pravastatin\", \"Pitavastatin\"],\n",
    "                \"Heart_Rhythm\": [\"Amiodarone\", \"Digoxin\", \"Diltiazem\", \"Verapamil\", \"Spironolactone\"]\n",
    "            },\n",
    "            \"CNS_Agents\": {\n",
    "                \"Antidepressants\": [\"Sertraline\", \"Fluoxetine\", \"Venlafaxine\", \"Duloxetine\", \"Bupropion\", \"Mirtazapine\"],\n",
    "                \"Antipsychotics\": [\"Quetiapine\", \"Risperidone\", \"Olanzapine\", \"Haloperidol\", \"Clozapine\"],\n",
    "                \"Anxiolytics\": [\"Alprazolam\", \"Diazepam\", \"Gabapentin\", \"Pregabalin\"]\n",
    "            },\n",
    "            \"Anti_Infectives\": {\n",
    "                \"Antibiotics\": [\"Ciprofloxacin\", \"Azithromycin\", \"Clarithromycin\", \"Rifampin\", \"Doxycycline\", \n",
    "                              \"Amoxicillin\", \"Metronidazole\", \"Trimethoprim-sulfamethoxazole\"],\n",
    "                \"Antifungals\": [\"Fluconazole\", \"Itraconazole\", \"Voriconazole\", \"Posaconazole\"],\n",
    "                \"Antivirals\": [\"Acyclovir\", \"Valacyclovir\", \"Oseltamivir\"]\n",
    "            },\n",
    "            \"Diabetes_Metabolic\": {\n",
    "                \"All\": [\"Metformin\", \"Glipizide\", \"Sitagliptin\", \"Empagliflozin\", \"Liraglutide\",\n",
    "                       \"Insulin glargine\", \"Insulin lispro\", \"Levothyroxine\", \"Methimazole\", \"Pioglitazone\"]\n",
    "            },\n",
    "            \"Pain_Analgesics\": {\n",
    "                \"All\": [\"Morphine\", \"Oxycodone\", \"Tramadol\", \"Hydromorphone\", \"Fentanyl\",\n",
    "                       \"Ibuprofen\", \"Celecoxib\", \"Meloxicam\", \"Acetaminophen\", \"Pregabalin\"]\n",
    "            },\n",
    "            \"Gastrointestinal\": {\n",
    "                \"All\": [\"Omeprazole\", \"Pantoprazole\", \"Esomeprazole\", \"Famotidine\", \"Ondansetron\",\n",
    "                       \"Metoclopramide\", \"Dicyclomine\", \"Sulfasalazine\", \"Mesalamine\", \"Prucalopride\"]\n",
    "            },\n",
    "            \"Respiratory\": {\n",
    "                \"All\": [\"Montelukast\", \"Fluticasone\", \"Budesonide\", \"Salbutamol\", \"Tiotropium\",\n",
    "                       \"Salmeterol\", \"Ipratropium\", \"Zafirlukast\", \"Theophylline\", \"Roflumilast\"]\n",
    "            },\n",
    "            \"Immunosuppressants\": {\n",
    "                \"All\": [\"Tacrolimus\", \"Cyclosporine\", \"Mycophenolate\", \"Azathioprine\", \"Sirolimus\"]\n",
    "            },\n",
    "            \"Oncology\": {\n",
    "                \"All\": [\"Methotrexate\", \"Cyclophosphamide\", \"Tamoxifen\", \"Letrozole\", \"Capecitabine\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def load_drugbank_data(self, filepath: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load and preprocess DrugBank data\n",
    "        \n",
    "        Args:\n",
    "            filepath (str): Path to DrugBank CSV file\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed DrugBank data with NaN values handled\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # Handle NaN values to ensure clean JSON output\n",
    "            df = df.fillna('')\n",
    "            print(f\"Successfully loaded DrugBank data with {len(df)} entries\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading DrugBank data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def find_drug_in_drugbank(self, drug_name: str, drugbank_df: pd.DataFrame, threshold: int = 85) -> Tuple[Optional[pd.Series], float]:\n",
    "        \"\"\"\n",
    "        Find drug in DrugBank using exact matching, aliases, and fuzzy matching\n",
    "        \n",
    "        Args:\n",
    "            drug_name (str): Name of drug to search for\n",
    "            drugbank_df (pd.DataFrame): DrugBank database\n",
    "            threshold (int): Minimum similarity score (0-100) for fuzzy matching\n",
    "            \n",
    "        Returns:\n",
    "            Tuple containing:\n",
    "            - pd.Series: Best matching drug data (or None if no match)\n",
    "            - float: Match confidence score\n",
    "        \"\"\"\n",
    "        # Step 1: Try exact match\n",
    "        exact_match = drugbank_df[drugbank_df['name'].str.lower() == drug_name.lower()]\n",
    "        if not exact_match.empty:\n",
    "            return exact_match.iloc[0], 100\n",
    "            \n",
    "        # Step 2: Check aliases for known alternative names\n",
    "        if drug_name in self.drug_aliases:\n",
    "            for alias in self.drug_aliases[drug_name]:\n",
    "                alias_match = drugbank_df[drugbank_df['name'].str.lower() == alias.lower()]\n",
    "                if not alias_match.empty:\n",
    "                    return alias_match.iloc[0], 100\n",
    "\n",
    "        # Step 3: Try fuzzy matching as fallback\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for _, row in drugbank_df.iterrows():\n",
    "            name_score = fuzz.ratio(drug_name.lower(), str(row['name']).lower())\n",
    "            if name_score > best_score and name_score >= threshold:\n",
    "                best_score = name_score\n",
    "                best_match = row\n",
    "\n",
    "        return best_match, best_score\n",
    "\n",
    "    def extract_drugbank_info(self, drug_data: pd.Series) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract relevant fields from DrugBank entry\n",
    "        \n",
    "        Args:\n",
    "            drug_data (pd.Series): Single drug entry from DrugBank\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Formatted drug information\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'drugbank_id': drug_data.get('drugbank_id', ''),\n",
    "            'mechanism_of_action': drug_data.get('mechanism_of_action', ''),\n",
    "            'pharmacodynamics': drug_data.get('pharmacodynamics', ''),\n",
    "            'toxicity': drug_data.get('toxicity', ''),\n",
    "            'drug_interactions': drug_data.get('drug_interactions', ''),\n",
    "            'indication': drug_data.get('indication', '')\n",
    "        }\n",
    "\n",
    "    def validate_drugs(self, drugbank_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Validate all drugs against DrugBank and prepare validation report\n",
    "        \n",
    "        Args:\n",
    "            drugbank_df (pd.DataFrame): DrugBank database\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Validation results containing found and missing drugs\n",
    "        \"\"\"\n",
    "        validation_results = {\n",
    "            'found_drugs': [],\n",
    "            'missing_drugs': []\n",
    "        }\n",
    "\n",
    "        total_drugs = 0\n",
    "        for category, subcategories in self.drug_categories.items():\n",
    "            for subcategory, drugs in subcategories.items():\n",
    "                total_drugs += len(drugs)\n",
    "                for drug in drugs:\n",
    "                    match, score = self.find_drug_in_drugbank(drug, drugbank_df)\n",
    "                    \n",
    "                    if match is not None:\n",
    "                        drug_info = self.extract_drugbank_info(match)\n",
    "                        validation_results['found_drugs'].append({\n",
    "                            'name': drug,\n",
    "                            'category': category,\n",
    "                            'subcategory': subcategory,\n",
    "                            'match_score': score,\n",
    "                            'drugbank_info': drug_info\n",
    "                        })\n",
    "                    else:\n",
    "                        validation_results['missing_drugs'].append({\n",
    "                            'name': drug,\n",
    "                            'category': category,\n",
    "                            'subcategory': subcategory\n",
    "                        })\n",
    "\n",
    "        print(f\"\\nValidation Summary:\")\n",
    "        print(f\"Total drugs checked: {total_drugs}\")\n",
    "        print(f\"Found in DrugBank: {len(validation_results['found_drugs'])}\")\n",
    "        print(f\"Missing from DrugBank: {len(validation_results['missing_drugs'])}\")\n",
    "        \n",
    "        return validation_results\n",
    "\n",
    "    def save_results(self, validation_results: Dict, output_file: str):\n",
    "        \"\"\"\n",
    "        Save validation results to JSON file with proper formatting\n",
    "        \n",
    "        Args:\n",
    "            validation_results (Dict): Validation results to save\n",
    "            output_file (str): Output file path\n",
    "        \"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(validation_results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nResults saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize validation framework\n",
    "    validator = DrugValidationFramework()\n",
    "    \n",
    "    # Load and preprocess DrugBank data\n",
    "    drugbank_df = validator.load_drugbank_data('drugbank_data.csv')\n",
    "    if drugbank_df is None:\n",
    "        return\n",
    "    \n",
    "    # Run validation\n",
    "    validation_results = validator.validate_drugs(drugbank_df)\n",
    "    \n",
    "    # Save results\n",
    "    validator.save_results(validation_results, 'drug_validation_results.json')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes  below creates visualizations of the cross validation carried out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "Data loaded successfully\n",
      "Preparing data for analysis...\n",
      "Processed 294 data points across 9 categories\n",
      "\n",
      "Starting visualization generation...\n",
      "Creating overall performance visualization...\n",
      "Saved overall_performance successfully\n",
      "Creating detailed metrics visualization...\n",
      "Saved detailed_metrics successfully\n",
      "Creating category analysis...\n",
      "Saved category_cardiovascular successfully\n",
      "Saved category_cns_agents successfully\n",
      "Saved category_pain_analgesics successfully\n",
      "Saved category_anti_infectives successfully\n",
      "Saved category_diabetes_metabolic successfully\n",
      "Saved category_gastrointestinal successfully\n",
      "Saved category_respiratory successfully\n",
      "Saved category_immunosuppressants successfully\n",
      "Saved category_oncology successfully\n",
      "Creating statistical summary...\n",
      "Saved statistical_summary successfully\n",
      "\n",
      "All visualizations completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from typing import Dict, List\n",
    "from scipy import stats\n",
    "\n",
    "class ThesisVisualizer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize visualizer with data and settings\"\"\"\n",
    "        # Image export settings\n",
    "        self.image_format = 'png'\n",
    "        self.image_scale = 2\n",
    "        self.image_width = 1200\n",
    "        self.image_height = 800\n",
    "        \n",
    "        # Load data\n",
    "        print(\"Loading data files...\")\n",
    "        try:\n",
    "            with open('strict_comparison_results.json', 'r') as f:\n",
    "                self.results = json.load(f)\n",
    "            with open('drug_validation_results.json', 'r') as f:\n",
    "                self.drugbank_data = json.load(f)\n",
    "            print(\"Data loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "        self.prepare_data()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare data for visualization\"\"\"\n",
    "        print(\"Preparing data for analysis...\")\n",
    "        data_list = []\n",
    "        drug_categories = {}\n",
    "        \n",
    "        # Extract drug categories\n",
    "        for drug in self.drugbank_data['found_drugs']:\n",
    "            drug_categories[drug['name']] = {\n",
    "                'category': drug['category'],\n",
    "                'subcategory': drug['subcategory']\n",
    "            }\n",
    "        \n",
    "        # Create detailed dataset\n",
    "        for drug_name, drug_data in self.results['detailed_results'].items():\n",
    "            category = drug_categories.get(drug_name, {'category': 'Unknown', 'subcategory': 'Unknown'})\n",
    "            for field, scores in drug_data['detailed_scores'].items():\n",
    "                data_list.append({\n",
    "                    'drug_name': drug_name,\n",
    "                    'category': category['category'],\n",
    "                    'subcategory': category['subcategory'],\n",
    "                    'comparison_type': field,\n",
    "                    'semantic_similarity': scores['semantic_similarity'],\n",
    "                    'technical_overlap': scores['technical_term_overlap'],\n",
    "                    'content_coverage': scores['content_coverage'],\n",
    "                    'weighted_score': scores['weighted_score']\n",
    "                })\n",
    "        \n",
    "        self.df = pd.DataFrame(data_list)\n",
    "        print(f\"Processed {len(self.df)} data points across {len(self.df['category'].unique())} categories\")\n",
    "\n",
    "    def save_figure(self, fig, filename_base: str):\n",
    "        \"\"\"Save figure in both HTML and image formats\"\"\"\n",
    "        try:\n",
    "            # Save interactive HTML\n",
    "            fig.write_html(f'visualizations/{filename_base}.html')\n",
    "            \n",
    "            # Save static image\n",
    "            fig.write_image(\n",
    "                f'visualizations/{filename_base}.{self.image_format}',\n",
    "                width=self.image_width,\n",
    "                height=self.image_height,\n",
    "                scale=self.image_scale\n",
    "            )\n",
    "            print(f\"Saved {filename_base} successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {filename_base}: {str(e)}\")\n",
    "\n",
    "    def create_overall_performance(self):\n",
    "        \"\"\"Create overall performance visualization\"\"\"\n",
    "        print(\"Creating overall performance visualization...\")\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Category Performance',\n",
    "                'Metric Distribution',\n",
    "                'Comparison Types',\n",
    "                'Time Series'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 1. Category Performance\n",
    "        cat_means = self.df.groupby('category')['weighted_score'].mean().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=cat_means['category'],\n",
    "                y=cat_means['weighted_score'],\n",
    "                name='Category Performance'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. Metric Distribution\n",
    "        metrics = ['semantic_similarity', 'technical_overlap', \n",
    "                  'content_coverage', 'weighted_score']\n",
    "        for metric in metrics:\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=self.df[metric],\n",
    "                    name=metric.replace('_', ' ').title()\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "        \n",
    "        # 3. Comparison Types\n",
    "        comp_means = self.df.groupby('comparison_type')['weighted_score'].mean().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=comp_means['comparison_type'],\n",
    "                y=comp_means['weighted_score'],\n",
    "                name='Comparison Types'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # 4. Time Series\n",
    "        self.df['sequence'] = self.df.groupby('comparison_type').cumcount()\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=self.df['sequence'],\n",
    "                y=self.df['weighted_score'],\n",
    "                mode='lines',\n",
    "                name='Performance Over Time'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=1000,\n",
    "            title_text='Overall Performance Analysis',\n",
    "            showlegend=True,\n",
    "            font=dict(size=14)\n",
    "        )\n",
    "        \n",
    "        self.save_figure(fig, 'overall_performance')\n",
    "\n",
    "    def create_detailed_metrics(self):\n",
    "        \"\"\"Create detailed metrics visualization\"\"\"\n",
    "        print(\"Creating detailed metrics visualization...\")\n",
    "        \n",
    "        # Define metrics first\n",
    "        metrics = ['semantic_similarity', 'technical_overlap', \n",
    "                  'content_coverage', 'weighted_score']\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Semantic vs Technical',\n",
    "                'Coverage vs Weighted',\n",
    "                'Category Distribution',\n",
    "                'Metric Correlations'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 1. Semantic vs Technical\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=self.df['semantic_similarity'],\n",
    "                y=self.df['technical_overlap'],\n",
    "                mode='markers',\n",
    "                name='Semantic vs Technical',\n",
    "                marker=dict(\n",
    "                    color=self.df['weighted_score'],\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=True\n",
    "                )\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. Coverage vs Weighted\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=self.df['content_coverage'],\n",
    "                y=self.df['weighted_score'],\n",
    "                mode='markers',\n",
    "                name='Coverage vs Weighted',\n",
    "                marker=dict(\n",
    "                    color=self.df['semantic_similarity'],\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=True\n",
    "                )\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. Category Distribution\n",
    "        for category in self.df['category'].unique():\n",
    "            cat_data = self.df[self.df['category'] == category]\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    y=cat_data['weighted_score'],\n",
    "                    name=category\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # 4. Metric Correlations\n",
    "        corr_matrix = self.df[metrics].corr()\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=corr_matrix,\n",
    "                x=[m.replace('_', ' ').title() for m in metrics],\n",
    "                y=[m.replace('_', ' ').title() for m in metrics],\n",
    "                colorscale='RdBu'\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=1000,\n",
    "            title_text='Detailed Metrics Analysis',\n",
    "            showlegend=True,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        self.save_figure(fig, 'detailed_metrics')\n",
    "\n",
    "    def create_category_analysis(self):\n",
    "        \"\"\"Create category-specific analysis\"\"\"\n",
    "        print(\"Creating category analysis...\")\n",
    "        for category in self.df['category'].unique():\n",
    "            cat_data = self.df[self.df['category'] == category]\n",
    "            \n",
    "            fig = make_subplots(\n",
    "                rows=2, cols=2,\n",
    "                subplot_titles=(\n",
    "                    'Metric Distribution',\n",
    "                    'Subcategory Performance',\n",
    "                    'Comparison Types',\n",
    "                    'Performance Timeline'\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Add visualizations for each category\n",
    "            # [Previous plotting code remains similar]\n",
    "            \n",
    "            fig.update_layout(\n",
    "                height=1000,\n",
    "                title_text=f'Analysis for {category}',\n",
    "                showlegend=True\n",
    "            )\n",
    "            \n",
    "            self.save_figure(fig, f'category_{category.lower().replace(\" \", \"_\")}')\n",
    "\n",
    "    def create_statistical_summary(self):\n",
    "        \"\"\"Create statistical summary visualization\"\"\"\n",
    "        print(\"Creating statistical summary...\")\n",
    "        # Perform statistical tests\n",
    "        categories = self.df['category'].unique()\n",
    "        f_stat, p_val = stats.f_oneway(*[\n",
    "            self.df[self.df['category'] == cat]['weighted_score'] \n",
    "            for cat in categories\n",
    "        ])\n",
    "        \n",
    "        # Create visualization\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=(\n",
    "                'Category Means with CI',\n",
    "                'Distribution Comparison',\n",
    "                'Statistical Tests',\n",
    "                'Performance Range'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Add statistical visualizations\n",
    "        # [Previous plotting code remains similar]\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=1000,\n",
    "            title_text='Statistical Analysis Summary',\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        self.save_figure(fig, 'statistical_summary')\n",
    "\n",
    "    def create_all_visualizations(self):\n",
    "        \"\"\"Create all visualizations\"\"\"\n",
    "        print(\"\\nStarting visualization generation...\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        import os\n",
    "        if not os.path.exists('visualizations'):\n",
    "            os.makedirs('visualizations')\n",
    "        \n",
    "        # Generate all visualizations\n",
    "        self.create_overall_performance()\n",
    "        self.create_detailed_metrics()\n",
    "        self.create_category_analysis()\n",
    "        self.create_statistical_summary()\n",
    "        \n",
    "        print(\"\\nAll visualizations completed successfully!\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        visualizer = ThesisVisualizer()\n",
    "        visualizer.create_all_visualizations()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in visualization generation: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
