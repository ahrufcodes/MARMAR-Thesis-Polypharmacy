"""
MARMAR Consistency Check Script

This script is designed to evaluate the consistency of outputs generated by MARMAR The program:

1. Simulates patient scenarios by providing specific medications, health conditions, and patient details, as explained in my research
2. Calls the API multiple times to retrieve responses for each scenario.
3. Uses ClinicalBERT to encode text responses and calculate similarity metrics to assess consistency.
4. Logs all API interactions and analysis steps for transparency.
5. Exports the results in various formats (CSV, LaTeX) for further analysis and documentation.
6. Visualizes similarity scores across fields for insight into output variability.

This script supports the research and development of MARMAR's capability to handle polypharmacy 
and personalized medical recommendations with reliability.
"""

# Import necessary libraries
import json
import openai
from openai import OpenAI
from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity
import statistics
import pandas as pd
from tabulate import tabulate
import logging
import seaborn as sns
import matplotlib.pyplot as plt

# Configure logging
logging.basicConfig(filename='consistency_check.log', level=logging.INFO, 
                    format='%(asctime)s - %(levelname)s - %(message)s')

# Set up OpenAI client
client = OpenAI(api_key='Your key here')

# Load ClinicalBERT tokenizer and model from Hugging Face
tokenizer = AutoTokenizer.from_pretrained("medicalai/ClinicalBERT")
model = AutoModel.from_pretrained("medicalai/ClinicalBERT")

def get_marmar_output(medications: str, conditions: str, patient_info: str, iteration: int) -> dict:
    """
    Calls the OpenAI API to get MARMAR's response for a given patient profile.
    """

    prompt = f"""System Role: You are an AI-powered pharmacist assistant with expertise in drug interactions, pharmacology, and personalized healthcare. Your knowledge is based on the latest peer-reviewed medical research and official drug databases. Provide your response in a structured JSON format.
User Role: Analyze the following medications, health conditions, and patient information:
Medications: {medications}
Health Conditions: {conditions}
Patient Information: {patient_info}
Prompt: Provide a very detailed analysis in the following JSON format without any additional text or formatting:
{{
  "interactionRiskLevel": "SEVERE" | "MODERATE" | "MILD",
  "generalExplanation": "Provide a clear, jargon-free explanation for users without medical background, focusing on practical implications and necessary actions",
  "detailedExplanation": "A more detailed explanation of the interactions, Include specific enzyme interactions, receptor effects, and pharmacokinetic/pharmacodynamic processes where relevant.",
  "generalAdvice": "General advice for managing these medications",
  "tailoredAdvice": "Provide a clear tailored advice Considering the user's age, gender, weight, and reported health conditions when providing tailored advice. Address potential side effects and how they might manifest given the user's specific situation",
  "pharmacologicalExplanation": "A more technical explanation of the pharmacological interactions diving into all that it entails, and the drugs constituents",
  "references": ["Reference 1", "Reference 2", "..."],
  "alternativeMedications": "If the interaction risk level is SEVERE or MODERATE, suggest alternative medications or adjusted treatment plans. Consider the user's health conditions and the primary purposes of the current medications when making suggestions. If not, set this field to null.",
  "dietaryPrecautions": [
    {{
      "name": "Name of food or drink",
      "explanation": "Explanation of why this food or drink should be avoided or consumed with caution"
    }}
  ],
  "missingInformation": ["List any missing fields from the input structure here"]
}}
**Guidelines:**
1. **Accuracy:** Ensure all information provided is accurate and based on reliable medical sources.
2. **Clarity:** Maintain clarity and conciseness in explanations to enhance user understanding.
3. **Format Strictness:** The response must be strictly in the specified JSON format without any additional characters, text, or markdown.
4. **Data Privacy:** Do not include any identifiable information about the user or disclose any PHI.
5. **Disclaimer:** Include a brief disclaimer at the end of the JSON indicating that the information provided is not a substitute for professional medical advice."""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "system", "content": "You are an AI-powered pharmacist assistant with expertise in drug interactions, pharmacology, and personalized healthcare."},
                      {"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=2000
        )
        logging.info(f"Iteration {iteration}: API call successful.")
    except openai.OpenAIError as e:
        logging.error(f"Iteration {iteration}: API call failed - {e}")
        return {}

    try:
        content = response.choices[0].message.content
        parsed_content = json.loads(content)
        logging.info(f"Iteration {iteration}: JSON parsed successfully.")
        return parsed_content
    except (KeyError, json.JSONDecodeError) as e:
        logging.error(f"Iteration {iteration}: JSON parsing failed - {e}")
        return {}

def encode_with_clinicalbert(texts: list) -> torch.Tensor:
    """
    Encodes a list of texts into ClinicalBERT embeddings.
    """
    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt", max_length=256)
    with torch.no_grad():
        outputs = model(**inputs)
    cls_embeddings = outputs.last_hidden_state[:, 0, :]
    return cls_embeddings

def calculate_similarity_with_clinicalbert(texts: list) -> float:
    """
    Calculates average cosine similarity between texts using ClinicalBERT embeddings.
    """
    texts = [text for text in texts if text]
    if len(texts) < 2:
        return 1.0

    embeddings = encode_with_clinicalbert(texts)
    cosine_sim_matrix = cosine_similarity(embeddings.numpy())
    
    n = len(texts)
    total_sim = sum(cosine_sim_matrix[i, j] for i in range(n) for j in range(i + 1, n))
    return total_sim / (n * (n - 1) / 2) if n > 1 else 0.0

def check_consistency(outputs: list) -> dict:
    consistency = {}
    risk_levels = [output.get('interactionRiskLevel', 'UNKNOWN') for output in outputs]
    consistency['interactionRiskLevel'] = {
        'consistent': len(set(risk_levels)) == 1,
        'values': risk_levels,
        'most_common': statistics.mode(risk_levels) if risk_levels else 'N/A'
    }

    string_fields = ['generalExplanation', 'detailedExplanation', 'generalAdvice', 'tailoredAdvice', 'pharmacologicalExplanation']
    for field in string_fields:
        values = [output.get(field, "") for output in outputs]
        consistency[field] = {
            'consistent': len(set(values)) == 1,
            'unique_values': len(set(values)),
            'similarity': calculate_similarity_with_clinicalbert(values)
        }

    return consistency

def visualize_similarity(consistency_results):
    similarity_scores = {field: value['similarity'] for field, value in consistency_results.items() if 'similarity' in value}
    df = pd.DataFrame(list(similarity_scores.items()), columns=['Field', 'Similarity'])
    plt.figure(figsize=(10, 6))
    sns.heatmap(df.set_index('Field').T, annot=True, cmap="YlGnBu", cbar=False)
    plt.title("Similarity Scores Across Fields")
    plt.show()

def save_all_outputs(outputs, filename):
    """
    Save all outputs to CSV for detailed post-analysis.
    """
    all_data = []
    for i, output in enumerate(outputs, start=1):
        row = {"Iteration": i}
        row.update(output)
        all_data.append(row)
    pd.DataFrame(all_data).to_csv(filename, index=False)

def main():
    test_cases = [
        {
            "medications": "Lisinopril, Metformin, Atorvastatin",
            "conditions": "Hypertension, Type 2 Diabetes, High Cholesterol",
            "patient_info": "65-year-old male, 180cm, 85kg"
        },
    ]

    num_iterations = 100
    for idx, case in enumerate(test_cases, start=1):
        medications = case["medications"]
        conditions = case["conditions"]
        patient_info = case["patient_info"]

        print(f"\n=== Test Case {idx} ===")
        print(f"Medications: {medications}")
        print(f"Health Conditions: {conditions}")
        print(f"Patient Information: {patient_info}\n")

        outputs = []
        for i in range(num_iterations):
            print(f"Iteration {i+1}/{num_iterations}")
            output = get_marmar_output(medications, conditions, patient_info, iteration=i+1)
            if output:
                outputs.append(output)

        # Save all outputs to CSV for detailed post-analysis
        save_all_outputs(outputs, f'all_outputs_test_case_{idx}.csv')
        print(f"All outputs saved to 'all_outputs_test_case_{idx}.csv'.")

        if outputs:
            consistency_results = check_consistency(outputs)

            test_inputs = {
                "Medications": medications,
                "Health Conditions": conditions,
                "Patient Information": patient_info
            }

            table = []
            headers = ["Field", "Consistent", "Details"]
            for key, value in consistency_results.items():
                if key == "interactionRiskLevel":
                    details = f"Values: {value['values']}\nMost Common: {value['most_common']}"
                else:
                    details = f"Unique Values: {value['unique_values']}\nSimilarity: {value['similarity']:.2f}"
                


                table.append([key, value.get('consistent', 'N/A'), details])

            df = pd.DataFrame(table, columns=headers)
            inputs_table = pd.DataFrame(list(test_inputs.items()), columns=["Category", "Details"])

            # Print Test Inputs and Consistency Results
            print("\nTest Inputs:")
            print(tabulate(inputs_table, headers="keys", tablefmt="grid"))
            print("\nConsistency Results:")
            print(tabulate(table, headers=headers, tablefmt="grid"))
            
            # Save consistency results to CSV
            df.to_csv(f'consistency_results_test_case_{idx}.csv', index=False)
            inputs_table.to_csv(f'test_inputs_test_case_{idx}.csv', index=False)
            print(f"\nConsistency results have been saved to 'consistency_results_test_case_{idx}.csv'.")
            print(f"Test inputs have been saved to 'test_inputs_test_case_{idx}.csv'.")

            # Generate LaTeX tables for consistency results and test inputs
            latex_table = df.to_latex(index=False, escape=False, longtable=True, caption=f"Consistency Check Results - Test Case {idx}", label=f"tab:consistency_results_{idx}")
            with open(f'consistency_results_test_case_{idx}.tex', 'w') as f:
                f.write(latex_table)
            print(f"LaTeX table has been saved to 'consistency_results_test_case_{idx}.tex'.")

            latex_inputs = inputs_table.to_latex(index=False, escape=False, longtable=True, caption=f"Test Inputs - Test Case {idx}", label=f"tab:test_inputs_{idx}")
            with open(f'test_inputs_test_case_{idx}.tex', 'w') as f:
                f.write(latex_inputs)
            print(f"LaTeX table for test inputs has been saved to 'test_inputs_test_case_{idx}.tex'.")

            # Visualize similarity scores
            visualize_similarity(consistency_results)

        else:
            print("No valid outputs to check consistency.")

if __name__ == "__main__":
    main()
